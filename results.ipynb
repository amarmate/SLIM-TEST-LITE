{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resid_build_sale_price': (372, 107),\n",
       " 'istanbul': (536, 7),\n",
       " 'airfoil': (1503, 5),\n",
       " 'bike_sharing': (731, 13),\n",
       " 'boston': (506, 13),\n",
       " 'breast_cancer': (569, 30),\n",
       " 'concrete_slump': (103, 7),\n",
       " 'concrete_strength': (1005, 8),\n",
       " 'diabetes': (442, 10),\n",
       " 'efficiency_heating': (768, 8),\n",
       " 'efficiency_cooling': (768, 8),\n",
       " 'forest_fires': (513, 43),\n",
       " 'ld50': (234, 626),\n",
       " 'ppb': (131, 626),\n",
       " 'bioav': (358, 241)}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle \n",
    "import os \n",
    "from scipy.stats import wilcoxon, ttest_rel\n",
    "from tabulate import tabulate\n",
    "\n",
    "from slim_gsgp_lib.datasets.data_loader import *\n",
    "datasets = [globals()[i] for i in globals() if 'load' in i][2:]\n",
    "datasets = datasets[:12] + datasets[13:]  # EXCLUDE PARKINSONS\n",
    "\n",
    "dataset_dict = {}\n",
    "df_datasets = {}\n",
    "for i, dataset in enumerate(datasets):\n",
    "    X,y = dataset()\n",
    "    name = dataset.__name__.split('load_')[1]\n",
    "    # id should be a two digit number\n",
    "    id = 'DA' + str(i).zfill(2)\n",
    "    dataset_dict[name] = id \n",
    "    df_datasets[name] = X.shape[0], X.shape[1]\n",
    "\n",
    "df_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the dictionary of params and results, as they were saved in separate files\n",
    "params_dict = {}\n",
    "results_dict = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    try:\n",
    "        dataset_name = dataset.__name__.split('load_')[1]\n",
    "        dataset_id = dataset_dict[dataset_name]\n",
    "\n",
    "        # The file will have this pattern: algorithm_scxo.pkl. \n",
    "        # We need to ensure only that for some settings (ex.: scxo) all the algorithms are present\n",
    "        avalaible_settings = []\n",
    "        for file in os.listdir(f'results/slim/{dataset_id}'):\n",
    "            # Get the different settings available \n",
    "            if len(file.split('_')) < 3:\n",
    "                continue\n",
    "            settings = file.split('_')[2].split('.')[0]\n",
    "            if settings not in avalaible_settings:\n",
    "                avalaible_settings.append(settings)\n",
    "        \n",
    "        for settings in avalaible_settings:\n",
    "            dict_params = {}\n",
    "            dict_results = {}\n",
    "            for suffix in ['MUL_ABS', 'MUL_SIG1', 'MUL_SIG2', 'SUM_ABS', 'SUM_SIG1', 'SUM_SIG2']:\n",
    "                try:\n",
    "                    # Parameters\n",
    "                    with open(f'params/{dataset_id}/{suffix}_{settings}.pkl', 'rb') as f:\n",
    "                        params = pickle.load(f)\n",
    "                    params = {suffix : params}\n",
    "                    dict_params.update(params)\n",
    "                    os.remove(f'params/{dataset_id}/{suffix}_{settings}.pkl')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in parameters {dataset_id} - {settings}: {e}\")\n",
    "\n",
    "                try:\n",
    "                    # Results\n",
    "                    with open(f'results/slim/{dataset_id}/{suffix}_{settings}.pkl', 'rb') as f:\n",
    "                        results = pickle.load(f)\n",
    "                    for k, v in results.items():\n",
    "                        if k not in dict_results:\n",
    "                            dict_results[k] = {}\n",
    "                        v = {suffix : v}\n",
    "                        dict_results[k].update(v)\n",
    "                    os.remove(f'results/slim/{dataset_id}/{suffix}_{settings}.pkl')\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in results {dataset_id} - {settings}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Dump the results\n",
    "            pickle.dump(dict_params, open(f'params/{dataset_id}/{settings}_3.pkl', 'wb'))\n",
    "            pickle.dump(dict_results, open(f'results/slim/{dataset_id}/{settings}_3.pkl', 'wb')) \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in processing dataset: {e}\")\n",
    "        continue       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significance(p_value, ratio):\n",
    "    if p_value >= 0.05:\n",
    "        return 'NSD'\n",
    "    elif ratio > 1:\n",
    "        return '-' * (1 + int(p_value < 0.01) + int(p_value < 0.001))\n",
    "    else:\n",
    "        return '+' * (1 + int(p_value < 0.01) + int(p_value < 0.001))\n",
    "\n",
    "def means_df(prefixes=['sc', 'scsm'],\n",
    "             datasets=None,\n",
    "             best=False,\n",
    "             rmse_compare=True,\n",
    "             decimals=3,\n",
    "             table=False):\n",
    "    \n",
    "    if datasets is None:\n",
    "        datasets = dataset_dict.keys()\n",
    "    \n",
    "    rows_rmse, rows_rmse_std, rows_size, rows_size_std = [], [], [], []\n",
    "    rmse_sig_test, size_sig_test = {}, {}\n",
    "\n",
    "    for dataset in datasets:\n",
    "        if dataset not in rmse_sig_test:\n",
    "            rmse_sig_test[dataset] = {}\n",
    "            size_sig_test[dataset] = {}\n",
    "\n",
    "        for prefix in prefixes: \n",
    "            if prefix not in rmse_sig_test[dataset]:\n",
    "                rmse_sig_test[dataset][prefix] = {}\n",
    "                size_sig_test[dataset][prefix] = {}\n",
    "                \n",
    "            with open(f'results/slim/{dataset_dict[dataset]}/{prefix}.pkl', 'rb') as f:\n",
    "                results = pickle.load(f)\n",
    "                rmse = results['rmse_compare'] if rmse_compare else results['rmse']\n",
    "                size = results['size']\n",
    "\n",
    "            for algo, values in rmse.items():\n",
    "\n",
    "                rows_rmse.append({'Dataset': dataset, 'Algorithm': algo, f'rmse_{prefix}': np.mean(values)})\n",
    "                rows_size.append({'Dataset': dataset, 'Algorithm': algo, f'size_{prefix}': np.mean(size[algo])})\n",
    "                rows_rmse_std.append({'Dataset': dataset, 'Algorithm': algo, f'rmse_std_{prefix}': np.std(values)})\n",
    "                rows_size_std.append({'Dataset': dataset, 'Algorithm': algo, f'size_std_{prefix}': np.std(size[algo])})\n",
    "                rmse_sig_test[dataset][prefix][algo] = np.array(values)\n",
    "                size_sig_test[dataset][prefix][algo] = np.array(size[algo])\n",
    "                \n",
    "    df_rmse = pd.DataFrame(rows_rmse)\n",
    "    df_size = pd.DataFrame(rows_size)\n",
    "    df_rmse_std = pd.DataFrame(rows_rmse_std)\n",
    "    df_size_std = pd.DataFrame(rows_size_std)\n",
    "\n",
    "    # Pivot tables and explicitly reorder columns based on the given prefixes\n",
    "    df_rmse = df_rmse.pivot_table(index=['Dataset', 'Algorithm'], values=[f'rmse_{p}' for p in prefixes], \n",
    "                                aggfunc='first').reset_index()\n",
    "    df_size = df_size.pivot_table(index=['Dataset', 'Algorithm'], values=[f'size_{p}' for p in prefixes], \n",
    "                                aggfunc='first').reset_index()\n",
    "    df_rmse_std = df_rmse_std.pivot_table(index=['Dataset', 'Algorithm'], values=[f'rmse_std_{p}' for p in prefixes],\n",
    "                                        aggfunc='first').reset_index()\n",
    "    df_size_std = df_size_std.pivot_table(index=['Dataset', 'Algorithm'], values=[f'size_std_{p}' for p in prefixes],\n",
    "                                        aggfunc='first').reset_index()\n",
    "    \n",
    "    # Explicitly reorder columns based on the prefixes\n",
    "    df_rmse = df_rmse[['Dataset', 'Algorithm'] + [f'rmse_{p}' for p in prefixes]]\n",
    "    df_size = df_size[['Dataset', 'Algorithm'] + [f'size_{p}' for p in prefixes]]\n",
    "    df_rmse_std = df_rmse_std[['Dataset', 'Algorithm'] + [f'rmse_std_{p}' for p in prefixes]]\n",
    "    df_size_std = df_size_std[['Dataset', 'Algorithm'] + [f'size_std_{p}' for p in prefixes]]\n",
    "    df_rmse['ratio_rmse'] = df_rmse[f'rmse_{prefixes[0]}'] / df_rmse[f'rmse_{prefixes[1]}']\n",
    "    df_size['ratio_size'] = df_size[f'size_{prefixes[0]}'] / df_size[f'size_{prefixes[1]}']\n",
    "\n",
    "    \n",
    "    # Calculate the statistcial significance\n",
    "    for dataset in rmse_sig_test.keys():\n",
    "        for algo in rmse_sig_test[dataset][prefixes[0]].keys():\n",
    "            for prefix in prefixes:\n",
    "                if prefix == prefixes[0]:\n",
    "                    continue\n",
    "                if len(rmse_sig_test[dataset][prefix][algo]) != len(rmse_sig_test[dataset][prefixes[0]][algo]):\n",
    "                    min_len = min(len(rmse_sig_test[dataset][prefix][algo]), len(rmse_sig_test[dataset][prefixes[0]][algo]))\n",
    "                    rmse_sig_test[dataset][prefix][algo] = rmse_sig_test[dataset][prefix][algo][:min_len]\n",
    "                    rmse_sig_test[dataset][prefixes[0]][algo] = rmse_sig_test[dataset][prefixes[0]][algo][:min_len]\n",
    "                    size_sig_test[dataset][prefix][algo] = size_sig_test[dataset][prefix][algo][:min_len]\n",
    "                    size_sig_test[dataset][prefixes[0]][algo] = size_sig_test[dataset][prefixes[0]][algo][:min_len]\n",
    "\n",
    "                _, p_value_rmse = wilcoxon(np.round(rmse_sig_test[dataset][prefix][algo] - rmse_sig_test[dataset][prefixes[0]][algo], decimals=8), zero_method='pratt', alternative='two-sided', method='approx')\n",
    "                _, p_value_size = wilcoxon(np.round(size_sig_test[dataset][prefix][algo] - size_sig_test[dataset][prefixes[0]][algo], decimals=8), zero_method='pratt', alternative='two-sided', method='approx')\n",
    "\n",
    "                df_rmse.loc[(df_rmse['Dataset'] == dataset) & (df_rmse['Algorithm'] == algo), 'rmse_significance'] = \\\n",
    "                    get_significance(\n",
    "                        p_value_rmse, \n",
    "                        df_rmse.loc[(df_rmse['Dataset'] == dataset) & (df_rmse['Algorithm'] == algo), f'ratio_rmse'].values[0]\n",
    "                    )\n",
    "\n",
    "                df_size.loc[(df_size['Dataset'] == dataset) & (df_size['Algorithm'] == algo), 'size_significance'] = \\\n",
    "                    get_significance(\n",
    "                        p_value_size, \n",
    "                        df_size.loc[(df_size['Dataset'] == dataset) & (df_size['Algorithm'] == algo), f'ratio_size'].values[0]\n",
    "                    )\n",
    "                \n",
    "    df_rmse.set_index(['Dataset', 'Algorithm'], inplace=True)\n",
    "    df_size.set_index(['Dataset', 'Algorithm'], inplace=True)\n",
    "    df_rmse_std.set_index(['Dataset', 'Algorithm'], inplace=True)\n",
    "    df_size_std.set_index(['Dataset', 'Algorithm'], inplace=True)\n",
    "\n",
    "\n",
    "    if best:\n",
    "        return _means_df_best(df_rmse, df_size, df_rmse_std, df_size_std, prefixes, rmse_compare, decimals, table)\n",
    "    \n",
    "    elif table:\n",
    "        df_combined = pd.concat([df_rmse, df_rmse_std, df_size, df_size_std], axis=1).reset_index()\n",
    "        df_combined = df_combined.round(decimals)\n",
    "        for prefix in prefixes:\n",
    "            df_combined[f'rmse_{prefix}'] = df_combined[f'rmse_{prefix}'].astype(str) + ' ± ' + df_combined[f'rmse_std_{prefix}'].astype(str)\n",
    "            df_combined[f'size_{prefix}'] = df_combined[f'size_{prefix}'].astype(str) + ' ± ' + df_combined[f'size_std_{prefix}'].astype(str)\n",
    "        df_combined = df_combined[[col for col in df_combined.columns if '_std' not in col]]\n",
    "        reordered_columns = (\n",
    "            ['Dataset', 'Algorithm'] +\n",
    "            [f'rmse_{p}' for p in prefixes] +\n",
    "            [f'size_{p}' for p in prefixes] +\n",
    "            ['ratio_rmse', 'ratio_size'] + \n",
    "            ['rmse_significance', 'size_significance']\n",
    "        )\n",
    "        df_combined = df_combined[reordered_columns]\n",
    "        print(tabulate(df_combined, headers='keys', tablefmt='fancy_grid', floatfmt=f\".{decimals}f\"))\n",
    "        return None\n",
    "    \n",
    "    # Combine df_rmse and df_size\n",
    "    df_combined = pd.concat([df_rmse, df_size], axis=1).reset_index()\n",
    "    df_combined = df_combined.round(decimals)\n",
    "    reordered_columns = (\n",
    "        ['Dataset', 'Algorithm'] +\n",
    "        [f'rmse_{p}' for p in prefixes] +\n",
    "        [f'size_{p}' for p in prefixes] +\n",
    "        ['ratio_rmse', 'ratio_size'] + \n",
    "        ['rmse_significance', 'size_significance']\n",
    "    )\n",
    "    df_combined = df_combined[reordered_columns]\n",
    "    df_combined.set_index(['Dataset', 'Algorithm'], inplace=True)\n",
    "    return df_combined.sort_values('ratio_rmse')    \n",
    "\n",
    "\n",
    "def _means_df_best(df_rmse, \n",
    "                   df_size, \n",
    "                   df_rmse_std,\n",
    "                   df_size_std,\n",
    "                   prefixes,\n",
    "                   rmse_compare=True,\n",
    "                   decimals=3, \n",
    "                   table=False):\n",
    "    best_dict_rmse, best_dict_size, best_dict_rmse_std, best_dict_size_std = {}, {}, {}, {}\n",
    "    prefix_columns = df_rmse.columns[:-2]\n",
    "\n",
    "    rmse_sig_test, size_sig_test = {}, {}\n",
    "    for prefix in prefix_columns:\n",
    "        best_indices = df_rmse.groupby('Dataset')[prefix].idxmin().values\n",
    "\n",
    "        for idx in best_indices:\n",
    "            dataset, algo = idx\n",
    "\n",
    "            # Significance test\n",
    "            dataset_id = dataset_dict[dataset]\n",
    "            with open(f'results/slim/{dataset_id}/{prefix.replace(\"rmse_\", \"\")}.pkl', 'rb') as f:\n",
    "                results = pickle.load(f)\n",
    "                rmse = results['rmse_compare'][algo] if rmse_compare else results['rmse'][algo]\n",
    "                size = results['size'][algo]\n",
    "            if dataset not in rmse_sig_test:\n",
    "                rmse_sig_test[dataset] = {}\n",
    "                size_sig_test[dataset] = {}\n",
    "            rmse_sig_test[dataset][prefix] = np.array(rmse)\n",
    "            size_sig_test[dataset][prefix] = np.array(size)\n",
    "\n",
    "            # Append to best_dict\n",
    "            rmse_value = df_rmse.loc[idx, prefix]\n",
    "            size_value = df_size.loc[idx, prefix.replace('rmse', 'size')]\n",
    "            rmse_value_std = df_rmse_std.loc[idx, f'rmse_std_{prefix.replace(\"rmse_\", \"\")}']\n",
    "            size_value_std = df_size_std.loc[idx, f'size_std_{prefix.replace(\"rmse_\", \"\")}']\n",
    "\n",
    "            if dataset not in best_dict_rmse:\n",
    "                best_dict_rmse[dataset] = []\n",
    "                best_dict_size[dataset] = []\n",
    "                best_dict_rmse_std[dataset] = []\n",
    "                best_dict_size_std[dataset] = []\n",
    "            best_dict_rmse[dataset].append(rmse_value)   \n",
    "            best_dict_size[dataset].append(size_value)\n",
    "            best_dict_rmse_std[dataset].append(rmse_value_std)\n",
    "            best_dict_size_std[dataset].append(size_value_std)\n",
    "\n",
    "    best_df_rmse = pd.DataFrame(best_dict_rmse).T\n",
    "    best_df_size = pd.DataFrame(best_dict_size).T\n",
    "    best_df_rmse_std = pd.DataFrame(best_dict_rmse_std).T\n",
    "    best_df_size_std = pd.DataFrame(best_dict_size_std).T\n",
    "    best_df_rmse.columns = prefix_columns\n",
    "    best_df_size.columns = [c.replace('rmse', 'size') for c in prefix_columns]\n",
    "    best_df_rmse_std.columns = [f'{c}_std' for c in prefix_columns]\n",
    "    best_df_size_std.columns = [f'{c}_std' for c in best_df_size.columns]\n",
    "    best_df_rmse['ratio_rmse'] = best_df_rmse[prefix_columns[0]] / best_df_rmse[prefix_columns[1]]\n",
    "    best_df_size['ratio_size'] = best_df_size[prefix_columns[0].replace('rmse', 'size')] / best_df_size[prefix_columns[1].replace('rmse', 'size')]\n",
    "\n",
    "    # For each dataset, calculate the significance test\n",
    "    for dataset in rmse_sig_test.keys():\n",
    "        for prefix in prefix_columns:\n",
    "            if prefix == prefix_columns[0]:\n",
    "                continue\n",
    "            # Check if the lengths are the same\n",
    "            if len(rmse_sig_test[dataset][prefix]) != len(rmse_sig_test[dataset][prefix_columns[0]]):\n",
    "                min_len = min(len(rmse_sig_test[dataset][prefix]), len(rmse_sig_test[dataset][prefix_columns[0]]))\n",
    "                rmse_sig_test[dataset][prefix] = rmse_sig_test[dataset][prefix][:min_len]\n",
    "                rmse_sig_test[dataset][prefix_columns[0]] = rmse_sig_test[dataset][prefix_columns[0]][:min_len]\n",
    "                size_sig_test[dataset][prefix] = size_sig_test[dataset][prefix][:min_len]\n",
    "                size_sig_test[dataset][prefix_columns[0]] = size_sig_test[dataset][prefix_columns[0]][:min_len]\n",
    "                \n",
    "            _, p_value_rmse = wilcoxon(np.round(rmse_sig_test[dataset][prefix] - rmse_sig_test[dataset][prefix_columns[0]], decimals=8), zero_method='pratt', alternative='two-sided', method='approx')\n",
    "            _, p_value_size = wilcoxon(np.round(size_sig_test[dataset][prefix] - size_sig_test[dataset][prefix_columns[0]], decimals=8), zero_method='pratt', alternative='two-sided', method='approx')\n",
    "            best_df_rmse.loc[dataset, 'rmse_significance'] = get_significance(p_value_rmse, best_df_rmse.loc[dataset, 'ratio_rmse'])\n",
    "            best_df_size.loc[dataset, 'size_significance'] = get_significance(p_value_size, best_df_size.loc[dataset, 'ratio_size'])\n",
    "\n",
    "    best_df_rmse.sort_values('ratio_rmse')\n",
    "    best_df = pd.concat([best_df_rmse, best_df_size], axis=1)\n",
    "    best_df = best_df.round(decimals)\n",
    "\n",
    "    # If table, we want to add the standard deviations in the rmses and sizes\n",
    "    if table:\n",
    "        best_df_std = pd.concat([best_df_rmse, best_df_size, best_df_rmse_std, best_df_size_std], axis=1)\n",
    "        best_df_std = best_df_std.round(decimals)\n",
    "        best_df_std = best_df_std.sort_values('ratio_rmse')\n",
    "        \n",
    "        best_df_std[f'rmse_{prefixes[0]}'] = best_df_std[f'rmse_{prefixes[0]}'].astype(str) + ' ± ' + best_df_std[f'rmse_{prefixes[0]}_std'].astype(str)\n",
    "        best_df_std[f'rmse_{prefixes[1]}'] = best_df_std[f'rmse_{prefixes[1]}'].astype(str) + ' ± ' + best_df_std[f'rmse_{prefixes[1]}_std'].astype(str)\n",
    "        best_df_std[f'size_{prefixes[0]}'] = best_df_std[f'size_{prefixes[0]}'].astype(str) + ' ± ' + best_df_std[f'size_{prefixes[0]}_std'].astype(str)\n",
    "        best_df_std[f'size_{prefixes[1]}'] = best_df_std[f'size_{prefixes[1]}'].astype(str) + ' ± ' + best_df_std[f'size_{prefixes[1]}_std'].astype(str)\n",
    "        best_df_std = best_df_std[[col for col in best_df_std.columns if '_std' not in col]]\n",
    "\n",
    "        # Now print the table\n",
    "        print(tabulate(best_df_std, headers='keys', tablefmt='fancy_grid', floatfmt=f\".{decimals}f\"))\n",
    "        return None\n",
    "\n",
    "    return best_df.sort_values('ratio_rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_scsm_3</th>\n",
       "      <th>rmse_sc_3</th>\n",
       "      <th>ratio_rmse</th>\n",
       "      <th>rmse_significance</th>\n",
       "      <th>size_scsm_3</th>\n",
       "      <th>size_sc_3</th>\n",
       "      <th>ratio_size</th>\n",
       "      <th>size_significance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bike_sharing</th>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.6157</td>\n",
       "      <td>++</td>\n",
       "      <td>105.70</td>\n",
       "      <td>87.80</td>\n",
       "      <td>1.2039</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efficiency_heating</th>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.8839</td>\n",
       "      <td>+</td>\n",
       "      <td>205.36</td>\n",
       "      <td>174.78</td>\n",
       "      <td>1.1750</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airfoil</th>\n",
       "      <td>0.1164</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.8867</td>\n",
       "      <td>+++</td>\n",
       "      <td>256.86</td>\n",
       "      <td>146.32</td>\n",
       "      <td>1.7555</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resid_build_sale_price</th>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>+</td>\n",
       "      <td>199.32</td>\n",
       "      <td>224.72</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>+++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efficiency_cooling</th>\n",
       "      <td>0.0815</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.9160</td>\n",
       "      <td>++</td>\n",
       "      <td>167.28</td>\n",
       "      <td>132.48</td>\n",
       "      <td>1.2627</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>0.2904</td>\n",
       "      <td>0.3106</td>\n",
       "      <td>0.9351</td>\n",
       "      <td>++</td>\n",
       "      <td>169.86</td>\n",
       "      <td>124.38</td>\n",
       "      <td>1.3657</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boston</th>\n",
       "      <td>0.1357</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.9404</td>\n",
       "      <td>++</td>\n",
       "      <td>99.60</td>\n",
       "      <td>104.84</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bioav</th>\n",
       "      <td>0.3266</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>0.9564</td>\n",
       "      <td>NSD</td>\n",
       "      <td>108.68</td>\n",
       "      <td>217.56</td>\n",
       "      <td>0.4995</td>\n",
       "      <td>+++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concrete_strength</th>\n",
       "      <td>0.1042</td>\n",
       "      <td>0.1054</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>NSD</td>\n",
       "      <td>211.80</td>\n",
       "      <td>124.58</td>\n",
       "      <td>1.7001</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>istanbul</th>\n",
       "      <td>0.0773</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.9902</td>\n",
       "      <td>NSD</td>\n",
       "      <td>49.54</td>\n",
       "      <td>48.20</td>\n",
       "      <td>1.0278</td>\n",
       "      <td>NSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>0.1790</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.9923</td>\n",
       "      <td>NSD</td>\n",
       "      <td>103.20</td>\n",
       "      <td>137.62</td>\n",
       "      <td>0.7499</td>\n",
       "      <td>+++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_fires</th>\n",
       "      <td>0.2345</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>1.0017</td>\n",
       "      <td>NSD</td>\n",
       "      <td>114.32</td>\n",
       "      <td>109.16</td>\n",
       "      <td>1.0473</td>\n",
       "      <td>NSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ld50</th>\n",
       "      <td>0.2264</td>\n",
       "      <td>0.2257</td>\n",
       "      <td>1.0030</td>\n",
       "      <td>NSD</td>\n",
       "      <td>91.48</td>\n",
       "      <td>72.88</td>\n",
       "      <td>1.2552</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concrete_slump</th>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.2616</td>\n",
       "      <td>1.0142</td>\n",
       "      <td>NSD</td>\n",
       "      <td>115.50</td>\n",
       "      <td>179.94</td>\n",
       "      <td>0.6419</td>\n",
       "      <td>+++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppb</th>\n",
       "      <td>0.3113</td>\n",
       "      <td>0.3065</td>\n",
       "      <td>1.0155</td>\n",
       "      <td>NSD</td>\n",
       "      <td>91.94</td>\n",
       "      <td>123.48</td>\n",
       "      <td>0.7446</td>\n",
       "      <td>+++</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        rmse_scsm_3  rmse_sc_3  ratio_rmse rmse_significance  \\\n",
       "bike_sharing                 0.0167     0.0271      0.6157                ++   \n",
       "efficiency_heating           0.0585     0.0662      0.8839                 +   \n",
       "airfoil                      0.1164     0.1313      0.8867               +++   \n",
       "resid_build_sale_price       0.0439     0.0480      0.9143                 +   \n",
       "efficiency_cooling           0.0815     0.0890      0.9160                ++   \n",
       "breast_cancer                0.2904     0.3106      0.9351                ++   \n",
       "boston                       0.1357     0.1443      0.9404                ++   \n",
       "bioav                        0.3266     0.3414      0.9564               NSD   \n",
       "concrete_strength            0.1042     0.1054      0.9885               NSD   \n",
       "istanbul                     0.0773     0.0781      0.9902               NSD   \n",
       "diabetes                     0.1790     0.1804      0.9923               NSD   \n",
       "forest_fires                 0.2345     0.2341      1.0017               NSD   \n",
       "ld50                         0.2264     0.2257      1.0030               NSD   \n",
       "concrete_slump               0.2654     0.2616      1.0142               NSD   \n",
       "ppb                          0.3113     0.3065      1.0155               NSD   \n",
       "\n",
       "                        size_scsm_3  size_sc_3  ratio_size size_significance  \n",
       "bike_sharing                 105.70      87.80      1.2039                 -  \n",
       "efficiency_heating           205.36     174.78      1.1750                --  \n",
       "airfoil                      256.86     146.32      1.7555               ---  \n",
       "resid_build_sale_price       199.32     224.72      0.8870               +++  \n",
       "efficiency_cooling           167.28     132.48      1.2627               ---  \n",
       "breast_cancer                169.86     124.38      1.3657               ---  \n",
       "boston                        99.60     104.84      0.9500                ++  \n",
       "bioav                        108.68     217.56      0.4995               +++  \n",
       "concrete_strength            211.80     124.58      1.7001               ---  \n",
       "istanbul                      49.54      48.20      1.0278               NSD  \n",
       "diabetes                     103.20     137.62      0.7499               +++  \n",
       "forest_fires                 114.32     109.16      1.0473               NSD  \n",
       "ld50                          91.48      72.88      1.2552               ---  \n",
       "concrete_slump               115.50     179.94      0.6419               +++  \n",
       "ppb                           91.94     123.48      0.7446               +++  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_df(prefixes=['scsm_3', 'sc_3'],\n",
    "         best=True, rmse_compare=False, decimals=4, table=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rmse_scsm_3</th>\n",
       "      <th>rmse_sc_3</th>\n",
       "      <th>size_scsm_3</th>\n",
       "      <th>size_sc_3</th>\n",
       "      <th>ratio_rmse</th>\n",
       "      <th>ratio_size</th>\n",
       "      <th>rmse_significance</th>\n",
       "      <th>size_significance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">bike_sharing</th>\n",
       "      <th>MUL_SIG2</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>144.82</td>\n",
       "      <td>40.66</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>3.5617</td>\n",
       "      <td>+++</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUM_ABS</th>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>123.44</td>\n",
       "      <td>22.32</td>\n",
       "      <td>0.2805</td>\n",
       "      <td>5.5305</td>\n",
       "      <td>+++</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL_ABS</th>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1285</td>\n",
       "      <td>177.02</td>\n",
       "      <td>27.04</td>\n",
       "      <td>0.2807</td>\n",
       "      <td>6.5466</td>\n",
       "      <td>+++</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL_SIG1</th>\n",
       "      <td>0.0327</td>\n",
       "      <td>0.0719</td>\n",
       "      <td>115.10</td>\n",
       "      <td>22.74</td>\n",
       "      <td>0.4555</td>\n",
       "      <td>5.0616</td>\n",
       "      <td>+++</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ld50</th>\n",
       "      <th>MUL_SIG2</th>\n",
       "      <td>0.2488</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>18.38</td>\n",
       "      <td>163.08</td>\n",
       "      <td>0.4695</td>\n",
       "      <td>0.1127</td>\n",
       "      <td>NSD</td>\n",
       "      <td>+++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resid_build_sale_price</th>\n",
       "      <th>MUL_ABS</th>\n",
       "      <td>0.0568</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>140.72</td>\n",
       "      <td>224.72</td>\n",
       "      <td>1.1850</td>\n",
       "      <td>0.6262</td>\n",
       "      <td>NSD</td>\n",
       "      <td>+++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airfoil</th>\n",
       "      <th>MUL_SIG2</th>\n",
       "      <td>0.1719</td>\n",
       "      <td>0.1434</td>\n",
       "      <td>50.34</td>\n",
       "      <td>62.52</td>\n",
       "      <td>1.1989</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>---</td>\n",
       "      <td>+++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ld50</th>\n",
       "      <th>SUM_SIG2</th>\n",
       "      <td>0.3195</td>\n",
       "      <td>0.2288</td>\n",
       "      <td>97.36</td>\n",
       "      <td>61.86</td>\n",
       "      <td>1.3965</td>\n",
       "      <td>1.5739</td>\n",
       "      <td>NSD</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bioav</th>\n",
       "      <th>MUL_ABS</th>\n",
       "      <td>0.5247</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>150.58</td>\n",
       "      <td>217.56</td>\n",
       "      <td>1.5368</td>\n",
       "      <td>0.6921</td>\n",
       "      <td>NSD</td>\n",
       "      <td>+++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ld50</th>\n",
       "      <th>MUL_ABS</th>\n",
       "      <td>0.4171</td>\n",
       "      <td>0.2257</td>\n",
       "      <td>137.86</td>\n",
       "      <td>72.88</td>\n",
       "      <td>1.8480</td>\n",
       "      <td>1.8916</td>\n",
       "      <td>-</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  rmse_scsm_3  rmse_sc_3  size_scsm_3  \\\n",
       "Dataset                Algorithm                                        \n",
       "bike_sharing           MUL_SIG2        0.0187     0.0761       144.82   \n",
       "                       SUM_ABS         0.0249     0.0888       123.44   \n",
       "                       MUL_ABS         0.0361     0.1285       177.02   \n",
       "                       MUL_SIG1        0.0327     0.0719       115.10   \n",
       "ld50                   MUL_SIG2        0.2488     0.5300        18.38   \n",
       "...                                       ...        ...          ...   \n",
       "resid_build_sale_price MUL_ABS         0.0568     0.0480       140.72   \n",
       "airfoil                MUL_SIG2        0.1719     0.1434        50.34   \n",
       "ld50                   SUM_SIG2        0.3195     0.2288        97.36   \n",
       "bioav                  MUL_ABS         0.5247     0.3414       150.58   \n",
       "ld50                   MUL_ABS         0.4171     0.2257       137.86   \n",
       "\n",
       "                                  size_sc_3  ratio_rmse  ratio_size  \\\n",
       "Dataset                Algorithm                                      \n",
       "bike_sharing           MUL_SIG2       40.66      0.2456      3.5617   \n",
       "                       SUM_ABS        22.32      0.2805      5.5305   \n",
       "                       MUL_ABS        27.04      0.2807      6.5466   \n",
       "                       MUL_SIG1       22.74      0.4555      5.0616   \n",
       "ld50                   MUL_SIG2      163.08      0.4695      0.1127   \n",
       "...                                     ...         ...         ...   \n",
       "resid_build_sale_price MUL_ABS       224.72      1.1850      0.6262   \n",
       "airfoil                MUL_SIG2       62.52      1.1989      0.8052   \n",
       "ld50                   SUM_SIG2       61.86      1.3965      1.5739   \n",
       "bioav                  MUL_ABS       217.56      1.5368      0.6921   \n",
       "ld50                   MUL_ABS        72.88      1.8480      1.8916   \n",
       "\n",
       "                                 rmse_significance size_significance  \n",
       "Dataset                Algorithm                                      \n",
       "bike_sharing           MUL_SIG2                +++               ---  \n",
       "                       SUM_ABS                 +++               ---  \n",
       "                       MUL_ABS                 +++               ---  \n",
       "                       MUL_SIG1                +++               ---  \n",
       "ld50                   MUL_SIG2                NSD               +++  \n",
       "...                                            ...               ...  \n",
       "resid_build_sale_price MUL_ABS                 NSD               +++  \n",
       "airfoil                MUL_SIG2                ---               +++  \n",
       "ld50                   SUM_SIG2                NSD               ---  \n",
       "bioav                  MUL_ABS                 NSD               +++  \n",
       "ld50                   MUL_ABS                   -               ---  \n",
       "\n",
       "[90 rows x 8 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_df(prefixes=['scsm_3', 'sc_3'],\n",
    "         best=False, rmse_compare=False, decimals=4, table=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse_significance\n",
       "NSD    42\n",
       "+++    27\n",
       "++      9\n",
       "-       5\n",
       "---     4\n",
       "+       2\n",
       "--      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_df(prefixes=['scsm_3', 'sc_3'],\n",
    "         best=False, rmse_compare=False, decimals=4, table=False).value_counts('rmse_significance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse_significance\n",
       "NSD    42\n",
       "+++    27\n",
       "++      9\n",
       "-       5\n",
       "---     4\n",
       "+       2\n",
       "--      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_df(prefixes=['scsm_3', 'sc_3'],\n",
    "         best=False, rmse_compare=False, decimals=4, table=False).value_counts('rmse_significance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = means_df(prefixes=['scsm', 'sc'],\n",
    "         best=False, rmse_compare=False, decimals=4, table=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = means_df(prefixes=['scsm', 'sc'],\n",
    "         best=False, rmse_compare=False, decimals=4, table=False)\n",
    "\n",
    "# For each dataset, apply a scaler to the rmse_scsm and rmse_sc columns\n",
    "maxs = df.groupby('Dataset').max()[['rmse_scsm', 'rmse_sc']].max(axis=1)\n",
    "mins = df.groupby('Dataset').min()[['rmse_scsm', 'rmse_sc']].min(axis=1)\n",
    "df['rmse_scsm_scaled'] = (df['rmse_scsm'] - mins) / (maxs - mins)\n",
    "df['rmse_sc_scaled'] = (df['rmse_sc'] - mins) / (maxs - mins)\n",
    "\n",
    "# Scale the sizes\n",
    "maxs = df.groupby('Dataset').max()[['size_scsm', 'size_sc']].max(axis=1)\n",
    "mins = df.groupby('Dataset').min()[['size_scsm', 'size_sc']].min(axis=1)\n",
    "df['size_scsm_scaled'] = (df['size_scsm'] - mins) / (maxs - mins)\n",
    "df['size_sc_scaled'] = (df['size_sc'] - mins) / (maxs - mins)\n",
    "\n",
    "# Create a score column\n",
    "df['score_scsm'] = df['rmse_scsm_scaled'] + 0.5 * df['size_scsm_scaled']\n",
    "df['score_sc'] = df['rmse_sc_scaled'] + 0.5 * df['size_sc_scaled']\n",
    "\n",
    "# Drop the scaled columns\n",
    "df.drop(columns=['rmse_scsm_scaled', 'rmse_sc_scaled', 'size_scsm_scaled', 'size_sc_scaled'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rmse_scsm</th>\n",
       "      <th>rmse_sc</th>\n",
       "      <th>size_scsm</th>\n",
       "      <th>size_sc</th>\n",
       "      <th>ratio_rmse</th>\n",
       "      <th>ratio_size</th>\n",
       "      <th>score_scsm</th>\n",
       "      <th>score_sc</th>\n",
       "      <th>scsm_better</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">bike_sharing</th>\n",
       "      <th>SUM_SIG2</th>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>85.7000</td>\n",
       "      <td>150.0000</td>\n",
       "      <td>0.4628</td>\n",
       "      <td>0.5713</td>\n",
       "      <td>0.167079</td>\n",
       "      <td>1.226552</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL_ABS</th>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>86.8333</td>\n",
       "      <td>77.1000</td>\n",
       "      <td>0.5429</td>\n",
       "      <td>1.1262</td>\n",
       "      <td>0.347993</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL_SIG2</th>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>87.0333</td>\n",
       "      <td>80.3000</td>\n",
       "      <td>0.5555</td>\n",
       "      <td>1.0839</td>\n",
       "      <td>0.066002</td>\n",
       "      <td>0.473513</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL_SIG1</th>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>90.0667</td>\n",
       "      <td>150.0333</td>\n",
       "      <td>0.5663</td>\n",
       "      <td>0.6003</td>\n",
       "      <td>0.260687</td>\n",
       "      <td>1.099878</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppb</th>\n",
       "      <th>MUL_SIG1</th>\n",
       "      <td>0.2841</td>\n",
       "      <td>0.4905</td>\n",
       "      <td>91.8000</td>\n",
       "      <td>181.4333</td>\n",
       "      <td>0.5793</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>0.119997</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>istanbul</th>\n",
       "      <th>MUL_SIG1</th>\n",
       "      <td>0.0738</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>91.7000</td>\n",
       "      <td>148.9667</td>\n",
       "      <td>1.1668</td>\n",
       "      <td>0.6156</td>\n",
       "      <td>1.052737</td>\n",
       "      <td>0.497525</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efficiency_cooling</th>\n",
       "      <th>SUM_ABS</th>\n",
       "      <td>0.0847</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>95.1000</td>\n",
       "      <td>278.6667</td>\n",
       "      <td>1.2018</td>\n",
       "      <td>0.3413</td>\n",
       "      <td>0.531005</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ppb</th>\n",
       "      <th>SUM_ABS</th>\n",
       "      <td>0.3847</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>87.3667</td>\n",
       "      <td>89.0667</td>\n",
       "      <td>1.4288</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.537106</td>\n",
       "      <td>0.040219</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUM_SIG1</th>\n",
       "      <td>0.4478</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>89.7000</td>\n",
       "      <td>172.9000</td>\n",
       "      <td>1.6402</td>\n",
       "      <td>0.5188</td>\n",
       "      <td>0.825886</td>\n",
       "      <td>0.501997</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL_ABS</th>\n",
       "      <td>0.4868</td>\n",
       "      <td>0.2816</td>\n",
       "      <td>99.0000</td>\n",
       "      <td>87.2667</td>\n",
       "      <td>1.7288</td>\n",
       "      <td>1.1345</td>\n",
       "      <td>1.046094</td>\n",
       "      <td>0.084976</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              rmse_scsm  rmse_sc  size_scsm   size_sc  \\\n",
       "Dataset            Algorithm                                            \n",
       "bike_sharing       SUM_SIG2      0.0269   0.0580    85.7000  150.0000   \n",
       "                   MUL_ABS       0.0341   0.0627    86.8333   77.1000   \n",
       "                   MUL_SIG2      0.0225   0.0405    87.0333   80.3000   \n",
       "                   MUL_SIG1      0.0299   0.0528    90.0667  150.0333   \n",
       "ppb                MUL_SIG1      0.2841   0.4905    91.8000  181.4333   \n",
       "...                                 ...      ...        ...       ...   \n",
       "istanbul           MUL_SIG1      0.0738   0.0633    91.7000  148.9667   \n",
       "efficiency_cooling SUM_ABS       0.0847   0.0705    95.1000  278.6667   \n",
       "ppb                SUM_ABS       0.3847   0.2692    87.3667   89.0667   \n",
       "                   SUM_SIG1      0.4478   0.2730    89.7000  172.9000   \n",
       "                   MUL_ABS       0.4868   0.2816    99.0000   87.2667   \n",
       "\n",
       "                              ratio_rmse  ratio_size  score_scsm  score_sc  \\\n",
       "Dataset            Algorithm                                                 \n",
       "bike_sharing       SUM_SIG2       0.4628      0.5713    0.167079  1.226552   \n",
       "                   MUL_ABS        0.5429      1.1262    0.347993  1.000000   \n",
       "                   MUL_SIG2       0.5555      1.0839    0.066002  0.473513   \n",
       "                   MUL_SIG1       0.5663      0.6003    0.260687  1.099878   \n",
       "ppb                MUL_SIG1       0.5793      0.5060    0.119997  1.500000   \n",
       "...                                  ...         ...         ...       ...   \n",
       "istanbul           MUL_SIG1       1.1668      0.6156    1.052737  0.497525   \n",
       "efficiency_cooling SUM_ABS        1.2018      0.3413    0.531005  0.500000   \n",
       "ppb                SUM_ABS        1.4288      0.9809    0.537106  0.040219   \n",
       "                   SUM_SIG1       1.6402      0.5188    0.825886  0.501997   \n",
       "                   MUL_ABS        1.7288      1.1345    1.046094  0.084976   \n",
       "\n",
       "                              scsm_better  \n",
       "Dataset            Algorithm               \n",
       "bike_sharing       SUM_SIG2          True  \n",
       "                   MUL_ABS           True  \n",
       "                   MUL_SIG2          True  \n",
       "                   MUL_SIG1          True  \n",
       "ppb                MUL_SIG1          True  \n",
       "...                                   ...  \n",
       "istanbul           MUL_SIG1         False  \n",
       "efficiency_cooling SUM_ABS          False  \n",
       "ppb                SUM_ABS          False  \n",
       "                   SUM_SIG1         False  \n",
       "                   MUL_ABS          False  \n",
       "\n",
       "[90 rows x 9 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get, for each dataset the best algorithm\n",
    "best_indices = df.groupby('Dataset')[['score_scsm', 'score_sc']].idxmin().values.flatten()\n",
    "best_df = df.loc[best_indices]\n",
    "\n",
    "# For which datasets is scsm better than sc? Youll need to pivot the table\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
