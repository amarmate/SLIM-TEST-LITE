{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resid_build_sale_price': (372, 107),\n",
       " 'istanbul': (536, 7),\n",
       " 'airfoil': (1503, 5),\n",
       " 'bike_sharing': (731, 13),\n",
       " 'boston': (506, 13),\n",
       " 'breast_cancer': (569, 30),\n",
       " 'concrete_slump': (103, 7),\n",
       " 'concrete_strength': (1005, 8),\n",
       " 'diabetes': (442, 10),\n",
       " 'efficiency_heating': (768, 8),\n",
       " 'efficiency_cooling': (768, 8),\n",
       " 'forest_fires': (513, 43),\n",
       " 'ld50': (234, 626),\n",
       " 'ppb': (131, 626),\n",
       " 'bioav': (358, 241)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle \n",
    "import os \n",
    "from scipy.stats import wilcoxon, ttest_rel\n",
    "from tabulate import tabulate\n",
    "\n",
    "from slim_gsgp_lib.datasets.data_loader import *\n",
    "datasets = [globals()[i] for i in globals() if 'load' in i][2:]\n",
    "datasets = datasets[:12] + datasets[13:]  # EXCLUDE PARKINSONS\n",
    "\n",
    "dataset_dict = {}\n",
    "df_datasets = {}\n",
    "for i, dataset in enumerate(datasets):\n",
    "    X,y = dataset()\n",
    "    name = dataset.__name__.split('load_')[1]\n",
    "    # id should be a two digit number\n",
    "    id = 'DA' + str(i).zfill(2)\n",
    "    dataset_dict[name] = id \n",
    "    df_datasets[name] = X.shape[0], X.shape[1]\n",
    "\n",
    "df_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significance(p_value, ratio):\n",
    "    if p_value >= 0.05:\n",
    "        return 'NSD'\n",
    "    elif ratio > 1:\n",
    "        return '-' * (1 + int(p_value < 0.01) + int(p_value < 0.001))\n",
    "    else:\n",
    "        return '+' * (1 + int(p_value < 0.01) + int(p_value < 0.001))\n",
    "\n",
    "def means_df(prefixes=['sc', 'scsm'],\n",
    "             datasets=None,\n",
    "             best=False,\n",
    "             rmse_compare=True,\n",
    "             decimals=3,\n",
    "             table=False):\n",
    "    \n",
    "    if datasets is None:\n",
    "        datasets = dataset_dict.keys()\n",
    "    \n",
    "    rows_rmse, rows_rmse_std, rows_size, rows_size_std = [], [], [], []\n",
    "    rmse_sig_test, size_sig_test = {}, {}\n",
    "\n",
    "    for dataset in datasets:\n",
    "        if dataset not in rmse_sig_test:\n",
    "            rmse_sig_test[dataset] = {}\n",
    "            size_sig_test[dataset] = {}\n",
    "\n",
    "        for prefix in prefixes: \n",
    "            if prefix not in rmse_sig_test[dataset]:\n",
    "                rmse_sig_test[dataset][prefix] = {}\n",
    "                size_sig_test[dataset][prefix] = {}\n",
    "                \n",
    "            with open(f'results/slim/{dataset_dict[dataset]}/{prefix}.pkl', 'rb') as f:\n",
    "                results = pickle.load(f)\n",
    "                rmse = results['rmse_compare'] if rmse_compare else results['rmse']\n",
    "                size = results['size']\n",
    "\n",
    "            for algo, values in rmse.items():\n",
    "\n",
    "                rows_rmse.append({'Dataset': dataset, 'Algorithm': algo, f'rmse_{prefix}': np.mean(values)})\n",
    "                rows_size.append({'Dataset': dataset, 'Algorithm': algo, f'size_{prefix}': np.mean(size[algo])})\n",
    "                rows_rmse_std.append({'Dataset': dataset, 'Algorithm': algo, f'rmse_std_{prefix}': np.std(values)})\n",
    "                rows_size_std.append({'Dataset': dataset, 'Algorithm': algo, f'size_std_{prefix}': np.std(size[algo])})\n",
    "                rmse_sig_test[dataset][prefix][algo] = np.array(values)\n",
    "                size_sig_test[dataset][prefix][algo] = np.array(size[algo])\n",
    "                \n",
    "    df_rmse = pd.DataFrame(rows_rmse)\n",
    "    df_size = pd.DataFrame(rows_size)\n",
    "    df_rmse_std = pd.DataFrame(rows_rmse_std)\n",
    "    df_size_std = pd.DataFrame(rows_size_std)\n",
    "\n",
    "    # Pivot tables and explicitly reorder columns based on the given prefixes\n",
    "    df_rmse = df_rmse.pivot_table(index=['Dataset', 'Algorithm'], values=[f'rmse_{p}' for p in prefixes], \n",
    "                                aggfunc='first').reset_index()\n",
    "    df_size = df_size.pivot_table(index=['Dataset', 'Algorithm'], values=[f'size_{p}' for p in prefixes], \n",
    "                                aggfunc='first').reset_index()\n",
    "    df_rmse_std = df_rmse_std.pivot_table(index=['Dataset', 'Algorithm'], values=[f'rmse_std_{p}' for p in prefixes],\n",
    "                                        aggfunc='first').reset_index()\n",
    "    df_size_std = df_size_std.pivot_table(index=['Dataset', 'Algorithm'], values=[f'size_std_{p}' for p in prefixes],\n",
    "                                        aggfunc='first').reset_index()\n",
    "    \n",
    "    # Explicitly reorder columns based on the prefixes\n",
    "    df_rmse = df_rmse[['Dataset', 'Algorithm'] + [f'rmse_{p}' for p in prefixes]]\n",
    "    df_size = df_size[['Dataset', 'Algorithm'] + [f'size_{p}' for p in prefixes]]\n",
    "    df_rmse_std = df_rmse_std[['Dataset', 'Algorithm'] + [f'rmse_std_{p}' for p in prefixes]]\n",
    "    df_size_std = df_size_std[['Dataset', 'Algorithm'] + [f'size_std_{p}' for p in prefixes]]\n",
    "    df_rmse['ratio_rmse'] = df_rmse[f'rmse_{prefixes[0]}'] / df_rmse[f'rmse_{prefixes[1]}']\n",
    "    df_size['ratio_size'] = df_size[f'size_{prefixes[0]}'] / df_size[f'size_{prefixes[1]}']\n",
    "\n",
    "    \n",
    "    # Calculate the statistcial significance\n",
    "    for dataset in rmse_sig_test.keys():\n",
    "        for algo in rmse_sig_test[dataset][prefixes[0]].keys():\n",
    "            for prefix in prefixes:\n",
    "                if prefix == prefixes[0]:\n",
    "                    continue\n",
    "                if len(rmse_sig_test[dataset][prefix][algo]) != len(rmse_sig_test[dataset][prefixes[0]][algo]):\n",
    "                    min_len = min(len(rmse_sig_test[dataset][prefix][algo]), len(rmse_sig_test[dataset][prefixes[0]][algo]))\n",
    "                    rmse_sig_test[dataset][prefix][algo] = rmse_sig_test[dataset][prefix][algo][:min_len]\n",
    "                    rmse_sig_test[dataset][prefixes[0]][algo] = rmse_sig_test[dataset][prefixes[0]][algo][:min_len]\n",
    "                    size_sig_test[dataset][prefix][algo] = size_sig_test[dataset][prefix][algo][:min_len]\n",
    "                    size_sig_test[dataset][prefixes[0]][algo] = size_sig_test[dataset][prefixes[0]][algo][:min_len]\n",
    "\n",
    "                _, p_value_rmse = wilcoxon(np.round(rmse_sig_test[dataset][prefix][algo] - rmse_sig_test[dataset][prefixes[0]][algo], decimals=8), zero_method='pratt', alternative='two-sided', method='approx')\n",
    "                _, p_value_size = wilcoxon(np.round(size_sig_test[dataset][prefix][algo] - size_sig_test[dataset][prefixes[0]][algo], decimals=8), zero_method='pratt', alternative='two-sided', method='approx')\n",
    "\n",
    "                df_rmse.loc[(df_rmse['Dataset'] == dataset) & (df_rmse['Algorithm'] == algo), 'rmse_significance'] = \\\n",
    "                    get_significance(\n",
    "                        p_value_rmse, \n",
    "                        df_rmse.loc[(df_rmse['Dataset'] == dataset) & (df_rmse['Algorithm'] == algo), f'ratio_rmse'].values[0]\n",
    "                    )\n",
    "\n",
    "                df_size.loc[(df_size['Dataset'] == dataset) & (df_size['Algorithm'] == algo), 'size_significance'] = \\\n",
    "                    get_significance(\n",
    "                        p_value_size, \n",
    "                        df_size.loc[(df_size['Dataset'] == dataset) & (df_size['Algorithm'] == algo), f'ratio_size'].values[0]\n",
    "                    )\n",
    "                \n",
    "    df_rmse.set_index(['Dataset', 'Algorithm'], inplace=True)\n",
    "    df_size.set_index(['Dataset', 'Algorithm'], inplace=True)\n",
    "    df_rmse_std.set_index(['Dataset', 'Algorithm'], inplace=True)\n",
    "    df_size_std.set_index(['Dataset', 'Algorithm'], inplace=True)\n",
    "\n",
    "\n",
    "    if best:\n",
    "        return _means_df_best(df_rmse, df_size, df_rmse_std, df_size_std, prefixes, rmse_compare, decimals, table)\n",
    "    \n",
    "    elif table:\n",
    "        df_combined = pd.concat([df_rmse, df_rmse_std, df_size, df_size_std], axis=1).reset_index()\n",
    "        df_combined = df_combined.round(decimals)\n",
    "        for prefix in prefixes:\n",
    "            df_combined[f'rmse_{prefix}'] = df_combined[f'rmse_{prefix}'].astype(str) + ' ± ' + df_combined[f'rmse_std_{prefix}'].astype(str)\n",
    "            df_combined[f'size_{prefix}'] = df_combined[f'size_{prefix}'].astype(str) + ' ± ' + df_combined[f'size_std_{prefix}'].astype(str)\n",
    "        df_combined = df_combined[[col for col in df_combined.columns if '_std' not in col]]\n",
    "        reordered_columns = (\n",
    "            ['Dataset', 'Algorithm'] +\n",
    "            [f'rmse_{p}' for p in prefixes] +\n",
    "            [f'size_{p}' for p in prefixes] +\n",
    "            ['ratio_rmse', 'ratio_size'] + \n",
    "            ['rmse_significance', 'size_significance']\n",
    "        )\n",
    "        df_combined = df_combined[reordered_columns]\n",
    "        print(tabulate(df_combined, headers='keys', tablefmt='fancy_grid', floatfmt=f\".{decimals}f\"))\n",
    "        return None\n",
    "    \n",
    "    # Combine df_rmse and df_size\n",
    "    df_combined = pd.concat([df_rmse, df_size], axis=1).reset_index()\n",
    "    df_combined = df_combined.round(decimals)\n",
    "    reordered_columns = (\n",
    "        ['Dataset', 'Algorithm'] +\n",
    "        [f'rmse_{p}' for p in prefixes] +\n",
    "        [f'size_{p}' for p in prefixes] +\n",
    "        ['ratio_rmse', 'ratio_size'] + \n",
    "        ['rmse_significance', 'size_significance']\n",
    "    )\n",
    "    df_combined = df_combined[reordered_columns]\n",
    "    df_combined.set_index(['Dataset', 'Algorithm'], inplace=True)\n",
    "    return df_combined.sort_values('ratio_rmse')    \n",
    "\n",
    "\n",
    "def _means_df_best(df_rmse, \n",
    "                   df_size, \n",
    "                   df_rmse_std,\n",
    "                   df_size_std,\n",
    "                   prefixes,\n",
    "                   rmse_compare=True,\n",
    "                   decimals=3, \n",
    "                   table=False):\n",
    "    best_dict_rmse, best_dict_size, best_dict_rmse_std, best_dict_size_std = {}, {}, {}, {}\n",
    "    prefix_columns = df_rmse.columns[:-1]\n",
    "\n",
    "    rmse_sig_test, size_sig_test = {}, {}\n",
    "    for prefix in prefix_columns:\n",
    "        best_indices = df_rmse.groupby('Dataset')[prefix].idxmin().values\n",
    "\n",
    "        for idx in best_indices:\n",
    "            dataset, algo = idx\n",
    "\n",
    "            # Significance test\n",
    "            dataset_id = dataset_dict[dataset]\n",
    "            with open(f'results/slim/{dataset_id}/{prefix.replace(\"rmse_\", \"\")}.pkl', 'rb') as f:\n",
    "                results = pickle.load(f)\n",
    "                rmse = results['rmse_compare'][algo] if rmse_compare else results['rmse'][algo]\n",
    "                size = results['size'][algo]\n",
    "            if dataset not in rmse_sig_test:\n",
    "                rmse_sig_test[dataset] = {}\n",
    "                size_sig_test[dataset] = {}\n",
    "            rmse_sig_test[dataset][prefix] = np.array(rmse)\n",
    "            size_sig_test[dataset][prefix] = np.array(size)\n",
    "\n",
    "            # Append to best_dict\n",
    "            rmse_value = df_rmse.loc[idx, prefix]\n",
    "            size_value = df_size.loc[idx, prefix.replace('rmse', 'size')]\n",
    "            rmse_value_std = df_rmse_std.loc[idx, f'rmse_std_{prefix.replace(\"rmse_\", \"\")}']\n",
    "            size_value_std = df_size_std.loc[idx, f'size_std_{prefix.replace(\"rmse_\", \"\")}']\n",
    "\n",
    "            if dataset not in best_dict_rmse:\n",
    "                best_dict_rmse[dataset] = []\n",
    "                best_dict_size[dataset] = []\n",
    "                best_dict_rmse_std[dataset] = []\n",
    "                best_dict_size_std[dataset] = []\n",
    "            best_dict_rmse[dataset].append(rmse_value)   \n",
    "            best_dict_size[dataset].append(size_value)\n",
    "            best_dict_rmse_std[dataset].append(rmse_value_std)\n",
    "            best_dict_size_std[dataset].append(size_value_std)\n",
    "\n",
    "    best_df_rmse = pd.DataFrame(best_dict_rmse).T\n",
    "    best_df_size = pd.DataFrame(best_dict_size).T\n",
    "    best_df_rmse_std = pd.DataFrame(best_dict_rmse_std).T\n",
    "    best_df_size_std = pd.DataFrame(best_dict_size_std).T\n",
    "    best_df_rmse.columns = prefix_columns\n",
    "    best_df_size.columns = [c.replace('rmse', 'size') for c in prefix_columns]\n",
    "    best_df_rmse_std.columns = [f'{c}_std' for c in prefix_columns]\n",
    "    best_df_size_std.columns = [f'{c}_std' for c in best_df_size.columns]\n",
    "    best_df_rmse['ratio_rmse'] = best_df_rmse[prefix_columns[0]] / best_df_rmse[prefix_columns[1]]\n",
    "    best_df_size['ratio_size'] = best_df_size[prefix_columns[0].replace('rmse', 'size')] / best_df_size[prefix_columns[1].replace('rmse', 'size')]\n",
    "\n",
    "    # For each dataset, calculate the significance test\n",
    "    for dataset in rmse_sig_test.keys():\n",
    "        for prefix in prefix_columns:\n",
    "            if prefix == prefix_columns[0]:\n",
    "                continue\n",
    "            # Check if the lengths are the same\n",
    "            if len(rmse_sig_test[dataset][prefix]) != len(rmse_sig_test[dataset][prefix_columns[0]]):\n",
    "                min_len = min(len(rmse_sig_test[dataset][prefix]), len(rmse_sig_test[dataset][prefix_columns[0]]))\n",
    "                rmse_sig_test[dataset][prefix] = rmse_sig_test[dataset][prefix][:min_len]\n",
    "                rmse_sig_test[dataset][prefix_columns[0]] = rmse_sig_test[dataset][prefix_columns[0]][:min_len]\n",
    "                size_sig_test[dataset][prefix] = size_sig_test[dataset][prefix][:min_len]\n",
    "                size_sig_test[dataset][prefix_columns[0]] = size_sig_test[dataset][prefix_columns[0]][:min_len]\n",
    "                \n",
    "            _, p_value_rmse = wilcoxon(np.round(rmse_sig_test[dataset][prefix] - rmse_sig_test[dataset][prefix_columns[0]], decimals=8), zero_method='pratt', alternative='two-sided', method='approx')\n",
    "            _, p_value_size = wilcoxon(np.round(size_sig_test[dataset][prefix] - size_sig_test[dataset][prefix_columns[0]], decimals=8), zero_method='pratt', alternative='two-sided', method='approx')\n",
    "            best_df_rmse.loc[dataset, 'rmse_significance'] = get_significance(p_value_rmse, best_df_rmse.loc[dataset, 'ratio_rmse'])\n",
    "            best_df_size.loc[dataset, 'size_significance'] = get_significance(p_value_size, best_df_size.loc[dataset, 'ratio_size'])\n",
    "\n",
    "    best_df_rmse.sort_values('ratio_rmse')\n",
    "    best_df = pd.concat([best_df_rmse, best_df_size], axis=1)\n",
    "    best_df = best_df.round(decimals)\n",
    "\n",
    "    # If table, we want to add the standard deviations in the rmses and sizes\n",
    "    if table:\n",
    "        best_df_std = pd.concat([best_df_rmse, best_df_size, best_df_rmse_std, best_df_size_std], axis=1)\n",
    "        best_df_std = best_df_std.round(decimals)\n",
    "        best_df_std = best_df_std.sort_values('ratio_rmse')\n",
    "        \n",
    "        # I need to have the rmse_scsm +- rmse_scsm_std and the same for size\n",
    "        best_df_std[f'rmse_{prefixes[0]}'] = best_df_std[f'rmse_{prefixes[0]}'].astype(str) + ' ± ' + best_df_std[f'rmse_{prefixes[0]}_std'].astype(str)\n",
    "        best_df_std[f'rmse_{prefixes[1]}'] = best_df_std[f'rmse_{prefixes[1]}'].astype(str) + ' ± ' + best_df_std[f'rmse_{prefixes[1]}_std'].astype(str)\n",
    "        best_df_std[f'size_{prefixes[0]}'] = best_df_std[f'size_{prefixes[0]}'].astype(str) + ' ± ' + best_df_std[f'size_{prefixes[0]}_std'].astype(str)\n",
    "        best_df_std[f'size_{prefixes[1]}'] = best_df_std[f'size_{prefixes[1]}'].astype(str) + ' ± ' + best_df_std[f'size_{prefixes[1]}_std'].astype(str)\n",
    "\n",
    "        # Drop columns that contain _std\n",
    "        best_df_std = best_df_std[[col for col in best_df_std.columns if '_std' not in col]]\n",
    "\n",
    "        # Now print the table\n",
    "        print(tabulate(best_df_std, headers='keys', tablefmt='fancy_grid', floatfmt=f\".{decimals}f\"))\n",
    "        return None\n",
    "\n",
    "    return best_df.sort_values('ratio_rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse_significance\n",
       "NSD    48\n",
       "+++    15\n",
       "+      13\n",
       "++     11\n",
       "-       1\n",
       "--      1\n",
       "---     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_df(prefixes=['scsm', 'sc'],\n",
    "         best=False, rmse_compare=False, decimals=4, table=False).value_counts('rmse_significance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = means_df(prefixes=['scsm', 'sc'],\n",
    "         best=False, rmse_compare=False, decimals=4, table=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = means_df(prefixes=['scsm', 'sc'],\n",
    "         best=False, rmse_compare=False, decimals=4, table=False)\n",
    "\n",
    "# For each dataset, apply a scaler to the rmse_scsm and rmse_sc columns\n",
    "maxs = df.groupby('Dataset').max()[['rmse_scsm', 'rmse_sc']].max(axis=1)\n",
    "mins = df.groupby('Dataset').min()[['rmse_scsm', 'rmse_sc']].min(axis=1)\n",
    "df['rmse_scsm_scaled'] = (df['rmse_scsm'] - mins) / (maxs - mins)\n",
    "df['rmse_sc_scaled'] = (df['rmse_sc'] - mins) / (maxs - mins)\n",
    "\n",
    "# Scale the sizes\n",
    "maxs = df.groupby('Dataset').max()[['size_scsm', 'size_sc']].max(axis=1)\n",
    "mins = df.groupby('Dataset').min()[['size_scsm', 'size_sc']].min(axis=1)\n",
    "df['size_scsm_scaled'] = (df['size_scsm'] - mins) / (maxs - mins)\n",
    "df['size_sc_scaled'] = (df['size_sc'] - mins) / (maxs - mins)\n",
    "\n",
    "# Create a score column\n",
    "df['score_scsm'] = df['rmse_scsm_scaled'] + 0.5 * df['size_scsm_scaled']\n",
    "df['score_sc'] = df['rmse_sc_scaled'] + 0.5 * df['size_sc_scaled']\n",
    "\n",
    "# Drop the scaled columns\n",
    "df.drop(columns=['rmse_scsm_scaled', 'rmse_sc_scaled', 'size_scsm_scaled', 'size_sc_scaled'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rmse_scsm</th>\n",
       "      <th>rmse_sc</th>\n",
       "      <th>size_scsm</th>\n",
       "      <th>size_sc</th>\n",
       "      <th>ratio_rmse</th>\n",
       "      <th>ratio_size</th>\n",
       "      <th>score_scsm</th>\n",
       "      <th>score_sc</th>\n",
       "      <th>scsm_better</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">bike_sharing</th>\n",
       "      <th>SUM_SIG2</th>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>85.7000</td>\n",
       "      <td>150.0000</td>\n",
       "      <td>0.4628</td>\n",
       "      <td>0.5713</td>\n",
       "      <td>0.167079</td>\n",
       "      <td>1.226552</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL_ABS</th>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>86.8333</td>\n",
       "      <td>77.1000</td>\n",
       "      <td>0.5429</td>\n",
       "      <td>1.1262</td>\n",
       "      <td>0.347993</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL_SIG2</th>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>87.0333</td>\n",
       "      <td>80.3000</td>\n",
       "      <td>0.5555</td>\n",
       "      <td>1.0839</td>\n",
       "      <td>0.066002</td>\n",
       "      <td>0.473513</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL_SIG1</th>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>90.0667</td>\n",
       "      <td>150.0333</td>\n",
       "      <td>0.5663</td>\n",
       "      <td>0.6003</td>\n",
       "      <td>0.260687</td>\n",
       "      <td>1.099878</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppb</th>\n",
       "      <th>MUL_SIG1</th>\n",
       "      <td>0.2841</td>\n",
       "      <td>0.4905</td>\n",
       "      <td>91.8000</td>\n",
       "      <td>181.4333</td>\n",
       "      <td>0.5793</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>0.119997</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>istanbul</th>\n",
       "      <th>MUL_SIG1</th>\n",
       "      <td>0.0738</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>91.7000</td>\n",
       "      <td>148.9667</td>\n",
       "      <td>1.1668</td>\n",
       "      <td>0.6156</td>\n",
       "      <td>1.052737</td>\n",
       "      <td>0.497525</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efficiency_cooling</th>\n",
       "      <th>SUM_ABS</th>\n",
       "      <td>0.0847</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>95.1000</td>\n",
       "      <td>278.6667</td>\n",
       "      <td>1.2018</td>\n",
       "      <td>0.3413</td>\n",
       "      <td>0.531005</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ppb</th>\n",
       "      <th>SUM_ABS</th>\n",
       "      <td>0.3847</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>87.3667</td>\n",
       "      <td>89.0667</td>\n",
       "      <td>1.4288</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.537106</td>\n",
       "      <td>0.040219</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUM_SIG1</th>\n",
       "      <td>0.4478</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>89.7000</td>\n",
       "      <td>172.9000</td>\n",
       "      <td>1.6402</td>\n",
       "      <td>0.5188</td>\n",
       "      <td>0.825886</td>\n",
       "      <td>0.501997</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL_ABS</th>\n",
       "      <td>0.4868</td>\n",
       "      <td>0.2816</td>\n",
       "      <td>99.0000</td>\n",
       "      <td>87.2667</td>\n",
       "      <td>1.7288</td>\n",
       "      <td>1.1345</td>\n",
       "      <td>1.046094</td>\n",
       "      <td>0.084976</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              rmse_scsm  rmse_sc  size_scsm   size_sc  \\\n",
       "Dataset            Algorithm                                            \n",
       "bike_sharing       SUM_SIG2      0.0269   0.0580    85.7000  150.0000   \n",
       "                   MUL_ABS       0.0341   0.0627    86.8333   77.1000   \n",
       "                   MUL_SIG2      0.0225   0.0405    87.0333   80.3000   \n",
       "                   MUL_SIG1      0.0299   0.0528    90.0667  150.0333   \n",
       "ppb                MUL_SIG1      0.2841   0.4905    91.8000  181.4333   \n",
       "...                                 ...      ...        ...       ...   \n",
       "istanbul           MUL_SIG1      0.0738   0.0633    91.7000  148.9667   \n",
       "efficiency_cooling SUM_ABS       0.0847   0.0705    95.1000  278.6667   \n",
       "ppb                SUM_ABS       0.3847   0.2692    87.3667   89.0667   \n",
       "                   SUM_SIG1      0.4478   0.2730    89.7000  172.9000   \n",
       "                   MUL_ABS       0.4868   0.2816    99.0000   87.2667   \n",
       "\n",
       "                              ratio_rmse  ratio_size  score_scsm  score_sc  \\\n",
       "Dataset            Algorithm                                                 \n",
       "bike_sharing       SUM_SIG2       0.4628      0.5713    0.167079  1.226552   \n",
       "                   MUL_ABS        0.5429      1.1262    0.347993  1.000000   \n",
       "                   MUL_SIG2       0.5555      1.0839    0.066002  0.473513   \n",
       "                   MUL_SIG1       0.5663      0.6003    0.260687  1.099878   \n",
       "ppb                MUL_SIG1       0.5793      0.5060    0.119997  1.500000   \n",
       "...                                  ...         ...         ...       ...   \n",
       "istanbul           MUL_SIG1       1.1668      0.6156    1.052737  0.497525   \n",
       "efficiency_cooling SUM_ABS        1.2018      0.3413    0.531005  0.500000   \n",
       "ppb                SUM_ABS        1.4288      0.9809    0.537106  0.040219   \n",
       "                   SUM_SIG1       1.6402      0.5188    0.825886  0.501997   \n",
       "                   MUL_ABS        1.7288      1.1345    1.046094  0.084976   \n",
       "\n",
       "                              scsm_better  \n",
       "Dataset            Algorithm               \n",
       "bike_sharing       SUM_SIG2          True  \n",
       "                   MUL_ABS           True  \n",
       "                   MUL_SIG2          True  \n",
       "                   MUL_SIG1          True  \n",
       "ppb                MUL_SIG1          True  \n",
       "...                                   ...  \n",
       "istanbul           MUL_SIG1         False  \n",
       "efficiency_cooling SUM_ABS          False  \n",
       "ppb                SUM_ABS          False  \n",
       "                   SUM_SIG1         False  \n",
       "                   MUL_ABS          False  \n",
       "\n",
       "[90 rows x 9 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get, for each dataset the best algorithm\n",
    "best_indices = df.groupby('Dataset')[['score_scsm', 'score_sc']].idxmin().values.flatten()\n",
    "best_df = df.loc[best_indices]\n",
    "\n",
    "# For which datasets is scsm better than sc? Youll need to pivot the table\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
